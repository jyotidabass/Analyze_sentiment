{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyze_sentiment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOs8CxSvyQlAlXSXNtL5WSq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Analyze_sentiment/blob/main/Analyze_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# import what we need\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn import naive_bayes\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "if __name__ == \"__main__\":\n",
        " # read the training data\n",
        " df = pd.read_csv(\"/content/sample_data/IMDB Dataset.csv\")\n",
        " # map positive to 1 and negative to 0\n",
        " df.sentiment = df.sentiment.apply(\n",
        " lambda x: 1 if x == \"positive\" else 0\n",
        " )\n",
        " # we create a new column called kfold and fill it with -1\n",
        " df[\"kfold\"] = -1\n",
        "\n",
        " # the next step is to randomize the rows of the data\n",
        " df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        " # fetch labels\n",
        " y = df.sentiment.values\n",
        "\n",
        " # initiate the kfold class from model_selection module\n",
        " kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        " # fill the new kfold column\n",
        " for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
        "  df.loc[v_, 'kfold'] = f\n",
        " # we go over the folds created\n",
        " for fold_ in range(5):\n",
        " # temporary dataframes for train and test\n",
        "   train_df = df[df.kfold != fold_].reset_index(drop=True)\n",
        "   test_df = df[df.kfold == fold_].reset_index(drop=True)\n",
        " # initialize CountVectorizer with NLTK's word_tokenize\n",
        " # function as tokenizer\n",
        " count_vec = CountVectorizer(\n",
        " tokenizer=word_tokenize,\n",
        " token_pattern=None\n",
        " )\n",
        " # fit count_vec on training data reviews\n",
        " count_vec.fit(train_df.review)\n",
        " # transform training and validation data reviews\n",
        " xtrain = count_vec.transform(train_df.review)\n",
        " xtest = count_vec.transform(test_df.review)\n",
        " # initialize naive bayes model\n",
        " model = naive_bayes.MultinomialNB()\n",
        " # fit the model on training data reviews and sentiment\n",
        " model.fit(xtrain, train_df.sentiment)\n",
        "# fit the model on training data reviews and sentiment\n",
        " model.fit(xtrain, train_df.sentiment)\n",
        " # make predictions on test data\n",
        " # threshold for predictions is 0.5\n",
        " preds = model.predict(xtest)\n",
        " # calculate accuracy\n",
        " accuracy = metrics.accuracy_score(test_df.sentiment, preds)\n",
        " print(f\"Fold: {fold_}\")\n",
        " print(f\"Accuracy = {accuracy}\")\n",
        " print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIgnwrxsi3if",
        "outputId": "1fe8a7e9-0b46-4c50-b53c-6bc56929f3eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Fold: 4\n",
            "Accuracy = 0.846\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "# create a corpus of sentences\n",
        "corpus = [\"hello, how are you?\",\n",
        " \"im getting bored at home. And you? What do you think?\",\n",
        " \"did you know about counts\",\n",
        " \"let's see if this works!\",\n",
        " \"YES!!!!\"\n",
        "]\n",
        "# initialize TfidfVectorizer with word_tokenize from nltk\n",
        "# as the tokenizer\n",
        "tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
        "# fit the vectorizer on corpus\n",
        "tfv.fit(corpus)\n",
        "corpus_transformed = tfv.transform(corpus)\n",
        "print(corpus_transformed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlGKmh3dkFeW",
        "outputId": "3913b520-55c2-4f2f-9375-f97fc2ad9838"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 27)\t0.2965698850220162\n",
            "  (0, 16)\t0.4428321995085722\n",
            "  (0, 14)\t0.4428321995085722\n",
            "  (0, 7)\t0.4428321995085722\n",
            "  (0, 4)\t0.35727423026525224\n",
            "  (0, 2)\t0.4428321995085722\n",
            "  (1, 27)\t0.35299699146792735\n",
            "  (1, 24)\t0.2635440111190765\n",
            "  (1, 22)\t0.2635440111190765\n",
            "  (1, 18)\t0.2635440111190765\n",
            "  (1, 15)\t0.2635440111190765\n",
            "  (1, 13)\t0.2635440111190765\n",
            "  (1, 12)\t0.2635440111190765\n",
            "  (1, 9)\t0.2635440111190765\n",
            "  (1, 8)\t0.2635440111190765\n",
            "  (1, 6)\t0.2635440111190765\n",
            "  (1, 4)\t0.42525129752567803\n",
            "  (1, 3)\t0.2635440111190765\n",
            "  (2, 27)\t0.31752680284846835\n",
            "  (2, 19)\t0.4741246485558491\n",
            "  (2, 11)\t0.4741246485558491\n",
            "  (2, 10)\t0.4741246485558491\n",
            "  (2, 5)\t0.4741246485558491\n",
            "  (3, 25)\t0.38775666010579296\n",
            "  (3, 23)\t0.38775666010579296\n",
            "  (3, 21)\t0.38775666010579296\n",
            "  (3, 20)\t0.38775666010579296\n",
            "  (3, 17)\t0.38775666010579296\n",
            "  (3, 1)\t0.38775666010579296\n",
            "  (3, 0)\t0.3128396318588854\n",
            "  (4, 26)\t0.2959842226518677\n",
            "  (4, 0)\t0.9551928286692534\n"
          ]
        }
      ]
    }
  ]
}